{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import Prettyplots as pp\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.signal import lfilter, gaussian, convolve\n",
    "\n",
    "'''\n",
    "    PURE UTILITY\n",
    "'''\n",
    "def print_progress(desc, amt):\n",
    "    print(\n",
    "        \"\\r{0}: [{1:50s}] {2:.1f}%\".format(\n",
    "            desc,\n",
    "            '#' * int(amt * 50), \n",
    "            amt*100\n",
    "        ), \n",
    "        end=\"\", flush=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_step(x, a):\n",
    "    boolean_arr = np.zeros_like(x).astype(np.int32)\n",
    "    for col, predicate in enumerate(a):\n",
    "        boolean_arr[x[:, col] >= predicate, col] = 1\n",
    "        \n",
    "    return boolean_arr\n",
    "\n",
    "def length(vector, axis=1):\n",
    "    return np.linalg.norm(vector, ord=None, axis=axis)\n",
    "\n",
    "def angle_btw(v1, v2):\n",
    "    return np.array([ np.arccos(np.dot(v1[r], v2[r]) / (length(v1[r], 0)*length(v2[r], 0))) \\\n",
    "              for r in range(0, v1.shape[0]) ])\n",
    "\n",
    "def lincomb(v_array, weights):\n",
    "    wsum = np.zeros((v_array.shape[0], ))\n",
    "    for col in range(0, v_array.shape[1]):\n",
    "        wsum += weights[col]*v_array[:, col]\n",
    "        \n",
    "    return wsum\n",
    "\n",
    "def curve_salience(curve, wlen=5, sig=1):\n",
    "    kern_lo = gaussian(wlen, std=sig)\n",
    "    kern_hi = gaussian(wlen, std=2.0*sig)\n",
    "    y_lo = convolve(curve, kern_lo, mode='same')\n",
    "    y_hi = convolve(curve, kern_hi, mode='same')\n",
    "    return np.abs(y_hi - y_lo)\n",
    "\n",
    "def candidate_keyframes(salience_curve):\n",
    "    return np.argwhere(salience_curve > np.mean(salience_curve))\n",
    "\n",
    "def cluster_keyframes_simple(keyframes, thresh=3):\n",
    "    itr = 0\n",
    "    cls = []\n",
    "    end = len(keyframes)\n",
    "    for i in range(0, end - 1):\n",
    "        d = keyframes[i + 1] - keyframes[i]\n",
    "        if d > thresh:\n",
    "            cls.append(keyframes[itr:i+1])\n",
    "            itr = i+1\n",
    "        \n",
    "    cls.append(keyframes[itr:end])\n",
    "    return cls\n",
    "\n",
    "def cluster_keyframes_kmeans(keyframes, n_clusters):\n",
    "    to_cluster = keyframes\n",
    "    dummy_axis = np.arange(len(keyframes))\n",
    "    X = np.vstack((to_cluster, dummy_axis)).T\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='random')\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    cls = [[] for _ in range(n_clusters)]\n",
    "    for k, l in zip(keyframes, kmeans.labels_):\n",
    "        cls[l].append(k)\n",
    "    \n",
    "    return X, kmeans.labels_, kmeans.cluster_centers_, cls\n",
    "\n",
    "def nearest_center_kmeans(samples, labels, centers):\n",
    "    \n",
    "    nearest = np.zeros_like(centers)\n",
    "    for idx, cen in enumerate(centers):\n",
    "        _slice = np.argwhere(labels == idx).flatten()\n",
    "        _samples = samples[_slice]\n",
    "        _dists = length(_samples - cen)\n",
    "        nearest[idx] = _samples[np.argmin(_dists)]\n",
    "    \n",
    "    return np.sort(nearest[:, 0])\n",
    "        \n",
    "def decimate_keyframes(kfcls, orig_curve):\n",
    "    kf = []\n",
    "    curve = orig_curve - np.mean(orig_curve)\n",
    "    for c in kfcls:\n",
    "        lmin = np.abs(np.min(curve[c]))\n",
    "        lmax = np.abs(np.max(curve[c]))\n",
    "\n",
    "        idx = 0\n",
    "        if lmin > lmax:\n",
    "            idx = np.argmin(curve[c])\n",
    "        else:\n",
    "            idx = np.argmax(curve[c])\n",
    "\n",
    "        kf.append(c[idx])\n",
    "    \n",
    "    kf.sort()\n",
    "    return kf\n",
    "\n",
    "def lpf_motion():\n",
    "    b = np.array([0.1526249789, 0.0333481282, 0.0777551903, 0.0667145281, 0.0138945068])\n",
    "    a = np.array([1, -1.7462227354, 1.7354077932, -0.8232679111, 0.1793463694])\n",
    "    return (b, a)\n",
    "\n",
    "def lpf_motion_d1():\n",
    "    b = np.array([0.1973679432, -0.0056567353, -0.0321850947, -0.1099445540, -0.0495815592])\n",
    "    a = np.array([1, -0.9870779094, 0.7774863652, -0.2206843188, 0.02813441289])\n",
    "    return (b, a)\n",
    "    \n",
    "def lpf_motion_d2():\n",
    "    b = np.array([-0.0795571277, 0.1390709784, -0.0479192600, -0.0031459045, -0.0084486862])\n",
    "    a = np.array([1, -1.571029458, 1.459212744, -0.7173743414, 0.1488005975])\n",
    "    return (b, a)\n",
    "\n",
    "def filter_motion(b, a, signal, dims):\n",
    "    out_signals = []\n",
    "    for dim in range(0, dims):\n",
    "        x = signal[:, dim]\n",
    "        y = lfilter(b, a, x)\n",
    "        out_signals.append(y)\n",
    "        \n",
    "    return np.vstack((tuple(out_signals))).T\n",
    "\n",
    "def lfderivator(coefs, filter_func, data_dict, dims=2):\n",
    "    return {\n",
    "        k:filter_func(coefs[0], coefs[1], p, dims) \\\n",
    "            for k, p in data_dict.items()\n",
    "    }\n",
    "\n",
    "def dict_operator(op_func=lambda x: x, in_dict={}):\n",
    "    return {k:op_func(p) for k, p in in_dict.items()}\n",
    "\n",
    "def dict2mat(in_dict, for_keys=None, transpose=True):\n",
    "    out_mat = None\n",
    "    if not for_keys:\n",
    "        out_mat = np.asarray(list(in_dict.values()))\n",
    "    else:\n",
    "        out_mat = np.array([in_dict[k] for k in for_keys])\n",
    "    \n",
    "    return out_mat.T if transpose else out_mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gesture(object):\n",
    "    \n",
    "    def __init__(self, laban_obj):\n",
    "        self.__keyframes = laban_obj._LabanApproximator__keyframes\n",
    "        \n",
    "        self.nframes = laban_obj.nframes\n",
    "        self.__weightefforts = np.zeros((self.nframes, ))\n",
    "        self.__timeefforts   = np.zeros((self.nframes, ))\n",
    "        self.__spaceefforts  = np.zeros((self.nframes, ))\n",
    "        \n",
    "        self.weight_weights = np.array([\n",
    "            0.1, 0.3, 0.3, 0.15, 0.15\n",
    "        ])\n",
    "        self.weight_effectors = [\n",
    "            'head', 'leftWrist', 'rightWrist', 'leftAnkle', 'rightAnkle'\n",
    "        ]\n",
    "        \n",
    "        self.time_weights = np.array([\n",
    "            0.3, 0.25, 0.25, 0.1, 0.1\n",
    "        ]) \n",
    "        self.time_effectors = [\n",
    "            'head', 'leftWrist', 'rightWrist', 'leftAnkle', 'rightAnkle'\n",
    "        ]\n",
    "        \n",
    "        self.space_weights = np.array([\n",
    "            0.1, 0.225, 0.225, 0.225, 0.225\n",
    "        ]) \n",
    "        self.space_effectors = [\n",
    "            'head', 'leftWrist', 'rightWrist', 'leftAnkle', 'rightAnkle'\n",
    "        ]\n",
    "                \n",
    "        motion_features = [\n",
    "            laban_obj.joint_speed,\n",
    "            laban_obj.joint_mgacc,\n",
    "            laban_obj.joint_pos\n",
    "        ]\n",
    "        \n",
    "        effectors = [\n",
    "            self.weight_effectors,\n",
    "            self.time_effectors,\n",
    "            self.space_effectors\n",
    "        ]\n",
    "        \n",
    "        effort_funcs = [\n",
    "            self.weight_effort,\n",
    "            self.time_effort,\n",
    "            self.space_effort\n",
    "        ]\n",
    "        \n",
    "        efforts = [\n",
    "            self.__weightefforts,\n",
    "            self.__timeefforts,\n",
    "            self.__spaceefforts\n",
    "        ]\n",
    "        \n",
    "        package = zip(motion_features, effectors, effort_funcs, efforts)\n",
    "        for x, y, z, w in package:\n",
    "            self.__push_effort(x, y, z, w)\n",
    "\n",
    "    def get_motion_features(self):\n",
    "        return np.vstack((\n",
    "            self.__weightefforts,\n",
    "            self.__timeefforts,\n",
    "            self.__spaceefforts\n",
    "        )).T\n",
    "    \n",
    "    def weight_effort(self, segment_matrix):\n",
    "        mat_sqr = np.power(segment_matrix, 2.)\n",
    "        mat_w = np.dot(mat_sqr, self.weight_weights)\n",
    "        return np.amax(mat_w)\n",
    "        \n",
    "    def time_effort(self, segment_matrix):\n",
    "        T = segment_matrix.shape[0]\n",
    "        mat_sum = np.sum(segment_matrix, axis=0) / T\n",
    "        return np.dot(mat_sum, self.time_weights)\n",
    "    \n",
    "    def space_effort(self, segment_matrix):\n",
    "        tot_displacement2d = segment_matrix[:, 1:] - segment_matrix[:, 0:-1]\n",
    "        tot_displacement1d = length(tot_displacement2d, axis=2)\n",
    "        tot_disp_sum = np.sum(tot_displacement1d, axis=1)\n",
    "        displacement2d = segment_matrix[:, -1] - segment_matrix[:, 0]\n",
    "        displacement1d = length(displacement2d)\n",
    "        disp_ratio = np.divide(displacement1d, tot_disp_sum + 0.001)\n",
    "        return np.dot(disp_ratio, self.space_weights)\n",
    "        \n",
    "    def __push_effort(self, mfeature, jointseg, effort_func, out_arr):\n",
    "        for idx, segment in enumerate(self.__iseg(mfeature, jointseg)):\n",
    "            out_arr[idx] = effort_func(segment)\n",
    "        \n",
    "    def __iseg(self, mfeature, jointseg):\n",
    "        isnd = len(mfeature['head'].shape) > 1\n",
    "        fmat = dict2mat(mfeature, jointseg, not isnd)\n",
    "        for i in range(0, len(self.__keyframes) - 1):\n",
    "            lo = self.__keyframes[i]\n",
    "            hi = self.__keyframes[i + 1]\n",
    "            yield fmat[:, lo:hi] if isnd else fmat[lo:hi, :]\n",
    "     \n",
    "    \n",
    "class LabanApproximator(object):\n",
    "    \n",
    "    h_pairs = [\n",
    "        ('rightShoulder', 'rightElbow'), ('rightElbow', 'rightWrist'),\n",
    "        ('leftShoulder', 'leftElbow'), ('leftElbow', 'leftWrist'),\n",
    "        ('rightHip', 'rightKnee'), ('rightKnee', 'rightAnkle'),\n",
    "        ('leftHip', 'leftKnee'), ('leftKnee', 'leftAnkle')\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, lma_segment):\n",
    "        self.scaling = 100.\n",
    "        \n",
    "        self.frameRate = lma_segment.meta_data['frameRate']\n",
    "        self.joint_keys = lma_segment.joint_keys\n",
    "        \n",
    "        f = filter_motion\n",
    "        data = dict_operator(self.world_scale, lma_segment.joint_data)\n",
    "        self.joint_pos = lfderivator(lpf_motion(),    f, data)\n",
    "        self.joint_vel = lfderivator(lpf_motion_d1(), f, data)\n",
    "        self.joint_acc = lfderivator(lpf_motion_d2(), f, data)\n",
    "        self.joint_speed = dict_operator(length, self.joint_vel)\n",
    "        self.joint_mgacc = dict_operator(length, self.joint_acc)\n",
    "        self.bone_angles = self.bone_angle_array() \n",
    "        \n",
    "        self.wlen = 5\n",
    "        self.sig  = 0.75\n",
    "        self.cluster_dist1 = self.wlen\n",
    "        self.n_clusters = 5\n",
    "        self.lin_weights = np.ones((self.bone_angles.shape[1], )) / self.bone_angles.shape[1]\n",
    "        \n",
    "        self.__keyframes, self.__rcurve = self.keyframes()\n",
    "        self.nframes = len(self.__keyframes) - 1\n",
    "        self.__gesture = Gesture(self)\n",
    "        \n",
    "\n",
    "    def get_motion_features(self):\n",
    "        return self.__gesture.get_motion_features()\n",
    "    \n",
    "    def world_scale(self, array):\n",
    "        return np.multiply(array, self.scaling)\n",
    "    \n",
    "    def bone_angle_array(self):\n",
    "        p = self.joint_pos\n",
    "        root = np.array([0, 0])\n",
    "        clav = (p['leftHip'] + p['rightHip']) / 2.\n",
    "        center_bone = clav - root\n",
    "                \n",
    "        return np.asarray([\n",
    "            angle_btw(v, center_bone) for v in [\n",
    "                p[bp[1]] - p[bp[0]] for bp in LabanApproximator.h_pairs\n",
    "            ]\n",
    "        ]).T\n",
    "        \n",
    "    def keyframes(self):\n",
    "        keyframes = []\n",
    "        a = self.bone_angles\n",
    "        for col in range(0, a.shape[1]):\n",
    "            curve = a[:, col]\n",
    "            salience = curve_salience(curve, self.wlen, self.sig)\n",
    "            candidkf = candidate_keyframes(salience)\n",
    "            kcluster = cluster_keyframes_simple(candidkf, self.cluster_dist1)\n",
    "            keyframes.append(decimate_keyframes(kcluster, curve))\n",
    "\n",
    "        k = reduce(np.union1d, tuple(keyframes))\n",
    "        _, _, _, cls = cluster_keyframes_kmeans(k, n_clusters=self.n_clusters)\n",
    "        ref_curve = lincomb(a, self.lin_weights)\n",
    "        out_keyframes = decimate_keyframes(cls, ref_curve)\n",
    "        #nearest_center_kmeans(X, lab, cen).astype(np.int32)\n",
    "        return (out_keyframes, ref_curve)\n",
    "    \n",
    "    def plt_keyframes(self, fignum=0, figsize=(10, 8)):\n",
    "        fig, axs = plt.subplots(2, 1, num=fignum, figsize=figsize)\n",
    "        pp.plt_keyframe_curve(axs[0], self.__keyframes, self.__rcurve)\n",
    "        pp.plt_keyframe_skeleton(axs[1], self.__keyframes, self.joint_pos, 200./self.scaling)\n",
    "        axs[1].set_xlim(min(self.__keyframes) - self.scaling / 2., max(self.__keyframes) + self.scaling / 2.)\n",
    "        axs[1].set_ylim(self.scaling / 2., -self.scaling / 2.)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMARunner(object):\n",
    "    \n",
    "    action_efforts = np.array([\n",
    "        [[0, 1], [2, 3]], [[4, 5], [6, 7]]\n",
    "    ])\n",
    "    \n",
    "    def __init__(self, video_segments):\n",
    "        self.lma_list = []\n",
    "        feature_list = []\n",
    "        \n",
    "        tot = len(video_segments) - 1\n",
    "        for elp, seg in enumerate(video_segments):\n",
    "            lma = LabanApproximator(seg)\n",
    "            self.lma_list.append(lma)\n",
    "            feature = lma.get_motion_features()\n",
    "            feature_list.append(feature)\n",
    "            print_progress('[*] Processing', elp/tot)\n",
    "        \n",
    "        self.nframes = len(self.lma_list)\n",
    "        self.ngestures = self.lma_list[0].nframes \n",
    "        self.motion_features_raw = np.vstack(tuple(feature_list))\n",
    "        self.motion_features_log = self.motion_features_raw.copy()\n",
    "        self.motion_features_log[:, 0:2] = np.log10(self.motion_features_log[:, 0:2])\n",
    "        \n",
    "        self.weight_thresh = np.mean(self.motion_features_log[:, 0])\n",
    "        self.time_thresh = np.mean(self.motion_features_log[:, 1])\n",
    "        self.space_thresh = 0.55\n",
    "        \n",
    "        self.action_effort_encoded = self.__action_effort(self.motion_features_log)\n",
    "        self.bea_encoded_ = self.action_effort_encoded.reshape((\n",
    "            self.nframes,\n",
    "            self.ngestures,\n",
    "            self.action_effort_encoded.shape[-1]\n",
    "        ))\n",
    "        \n",
    "        #self.action_effort_encoded_ = self.action_effort_encoded.reshape((\n",
    "        #    self.nframes, \n",
    "        #    self.ngestures\n",
    "        #))\n",
    "        \n",
    "    def __basic_effort(self, effort_features):\n",
    "        predicates = zip([self.weight_thresh, self.time_thresh, self.space_thresh])\n",
    "        return np_step(effort_features, predicates)\n",
    "    \n",
    "    def __action_effort(self, effort_features):\n",
    "        binary_encoding = self.__basic_effort(effort_features)\n",
    "        decimal_encoding = binary_encoding.dot(\n",
    "            1 << np.arange(binary_encoding.shape[-1] - 1, -1, -1)\n",
    "        ).astype(np.int32)\n",
    "        \n",
    "        idx = np.vstack((np.arange(binary_encoding.shape[0]), decimal_encoding)).T\n",
    "        one_hot = np.zeros((effort_features.shape[0], 8))\n",
    "        one_hot[idx[:, 0], idx[:, 1]] = 1\n",
    "        \n",
    "        return one_hot\n",
    "        #return LMARunner.action_efforts[p[:, 0], p[:, 1], p[:, 2]]\n",
    "    \n",
    "    def dataframe(self):\n",
    "        '''\n",
    "            TODO:\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def plot_keyframes_for(self, frame_num, fignum=0):\n",
    "        self.lma_list[frame_num].plt_keyframes(fignum=fignum)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
