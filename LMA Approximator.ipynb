{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import Prettyplots as pp\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.signal import lfilter, gaussian, convolve\n",
    "\n",
    "'''\n",
    "    PURE UTILITY\n",
    "'''\n",
    "def print_progress(desc, amt):\n",
    "    print(\n",
    "        \"\\r{0}: [{1:50s}] {2:.1f}%\".format(\n",
    "            desc,\n",
    "            '#' * int(amt * 50), \n",
    "            amt*100\n",
    "        ), \n",
    "        end=\"\", flush=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_step(x, a):\n",
    "    boolean_arr = np.zeros_like(x).astype(np.int32)\n",
    "    for col, predicate in enumerate(a):\n",
    "        boolean_arr[x[:, col] >= predicate, col] = 1\n",
    "        \n",
    "    return boolean_arr\n",
    "\n",
    "def curvature(curve_vel, curve_acc):\n",
    "    dx_dt, dy_dt = curve_vel[:, 0], curve_vel[:, 1]\n",
    "    d2x_dt2, d2y_dt2 = curve_acc[:, 0], curve_acc[:, 1]\n",
    "    return np.abs(d2x_dt2 * dy_dt - dx_dt * d2y_dt2) / (dx_dt * dx_dt + dy_dt * dy_dt)**1.5\n",
    "    \n",
    "def length(vector, axis=1):\n",
    "    return np.linalg.norm(vector, ord=None, axis=axis)\n",
    "\n",
    "def angle_btw(v1, v2):\n",
    "    return np.array([ np.arccos(np.dot(v1[r], v2[r]) / (length(v1[r], 0)*length(v2[r], 0))) \\\n",
    "              for r in range(0, v1.shape[0]) ])\n",
    "\n",
    "def lincomb(v_array, weights):\n",
    "    wsum = np.zeros((v_array.shape[0], ))\n",
    "    for col in range(0, v_array.shape[1]):\n",
    "        wsum += weights[col]*v_array[:, col]\n",
    "        \n",
    "    return wsum\n",
    "\n",
    "def curve_salience(curve, wlen=5, sig=1):\n",
    "    kern_lo = gaussian(wlen, std=sig)\n",
    "    kern_hi = gaussian(wlen, std=2.0*sig)\n",
    "    y_lo = convolve(curve, kern_lo, mode='same')\n",
    "    y_hi = convolve(curve, kern_hi, mode='same')\n",
    "    return np.abs(y_hi - y_lo)\n",
    "\n",
    "def candidate_keyframes(salience_curve):\n",
    "    return np.argwhere(salience_curve > np.mean(salience_curve))\n",
    "\n",
    "def cluster_keyframes_simple(keyframes, thresh=3):\n",
    "    itr = 0\n",
    "    cls = []\n",
    "    end = len(keyframes)\n",
    "    for i in range(0, end - 1):\n",
    "        d = keyframes[i + 1] - keyframes[i]\n",
    "        if d > thresh:\n",
    "            cls.append(keyframes[itr:i+1])\n",
    "            itr = i+1\n",
    "        \n",
    "    cls.append(keyframes[itr:end])\n",
    "    return cls\n",
    "\n",
    "def cluster_keyframes_kmeans(keyframes, n_clusters):\n",
    "    to_cluster = keyframes\n",
    "    dummy_axis = np.arange(len(keyframes))\n",
    "    X = np.vstack((to_cluster, dummy_axis)).T\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, init='random')\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    cls = [[] for _ in range(n_clusters)]\n",
    "    for k, l in zip(keyframes, kmeans.labels_):\n",
    "        cls[l].append(k)\n",
    "    \n",
    "    return X, kmeans.labels_, kmeans.cluster_centers_, cls\n",
    "\n",
    "def nearest_center_kmeans(samples, labels, centers):\n",
    "    \n",
    "    nearest = np.zeros_like(centers)\n",
    "    for idx, cen in enumerate(centers):\n",
    "        _slice = np.argwhere(labels == idx).flatten()\n",
    "        _samples = samples[_slice]\n",
    "        _dists = length(_samples - cen)\n",
    "        nearest[idx] = _samples[np.argmin(_dists)]\n",
    "    \n",
    "    return np.sort(nearest[:, 0])\n",
    "        \n",
    "def decimate_keyframes(kfcls, orig_curve):\n",
    "    kf = []\n",
    "    curve = orig_curve - np.mean(orig_curve)\n",
    "    for c in kfcls:\n",
    "        lmin = np.abs(np.min(curve[c]))\n",
    "        lmax = np.abs(np.max(curve[c]))\n",
    "\n",
    "        idx = 0\n",
    "        if lmin > lmax:\n",
    "            idx = np.argmin(curve[c])\n",
    "        else:\n",
    "            idx = np.argmax(curve[c])\n",
    "\n",
    "        kf.append(c[idx])\n",
    "    \n",
    "    kf.sort()\n",
    "    return kf\n",
    "\n",
    "def lpf_motion():\n",
    "    b = np.array([0.1526249789, 0.0333481282, 0.0777551903, 0.0667145281, 0.0138945068])\n",
    "    a = np.array([1, -1.7462227354, 1.7354077932, -0.8232679111, 0.1793463694])\n",
    "    return (b, a)\n",
    "\n",
    "def lpf_motion_d1():\n",
    "    b = np.array([0.1973679432, -0.0056567353, -0.0321850947, -0.1099445540, -0.0495815592])\n",
    "    a = np.array([1, -0.9870779094, 0.7774863652, -0.2206843188, 0.02813441289])\n",
    "    return (b, a)\n",
    "    \n",
    "def lpf_motion_d2():\n",
    "    b = np.array([-0.0795571277, 0.1390709784, -0.0479192600, -0.0031459045, -0.0084486862])\n",
    "    a = np.array([1, -1.571029458, 1.459212744, -0.7173743414, 0.1488005975])\n",
    "    return (b, a)\n",
    "\n",
    "def filter_motion(b, a, signal, dims):\n",
    "    out_signals = []\n",
    "    for dim in range(0, dims):\n",
    "        x = signal[:, dim]\n",
    "        y = lfilter(b, a, x)\n",
    "        out_signals.append(y)\n",
    "        \n",
    "    return np.vstack((tuple(out_signals))).T\n",
    "\n",
    "def lfderivator(coefs, filter_func, data_dict, dims=2):\n",
    "    return {\n",
    "        k:filter_func(coefs[0], coefs[1], p, dims) \\\n",
    "            for k, p in data_dict.items()\n",
    "    }\n",
    "\n",
    "def dict_operator(op_func=lambda x: x, in_dict={}):\n",
    "    return {k:op_func(p) for k, p in in_dict.items()}\n",
    "\n",
    "def dict2mat(in_dict, for_keys=None, transpose=True):\n",
    "    out_mat = None\n",
    "    if not for_keys:\n",
    "        out_mat = np.asarray(list(in_dict.values()))\n",
    "    else:\n",
    "        out_mat = np.array([in_dict[k] for k in for_keys])\n",
    "    \n",
    "    return out_mat.T if transpose else out_mat\n",
    "\n",
    "def velocity(x, dt=1.):\n",
    "    v = x[2:] - x[0:-2]\n",
    "    v_pad = np.pad(v, (1, 1), 'edge')\n",
    "    return np.divide(v_pad, 2.*dt)\n",
    "\n",
    "def acceleration(x, dt=1.):\n",
    "    a = x[2:] - 2.*x[1:-1] + x[0:-2]\n",
    "    a_pad = np.pad(a, (1, 1), 'edge')\n",
    "    return np.divide(a_pad, dt**2)\n",
    "\n",
    "def jerk(x, dt=1.):\n",
    "    j = x[4:] - 2.*x[3:-1] + 2.*x[0:-4] - x[1:-3]\n",
    "    j_pad = np.pad(j, (2, 2), 'edge')\n",
    "    return np.divide(j_pad, 2.*dt**3)\n",
    "\n",
    "def filter_motion2(x, func, fs=1.):\n",
    "    out_signals = []\n",
    "    for col in range(x.shape[1]):\n",
    "        y = func(x[:, col], fs)\n",
    "        out_signals.append(y)\n",
    "        \n",
    "    return np.vstack(tuple(out_signals)).T\n",
    "\n",
    "def rawderivator(func, data_dict, fs=1.):\n",
    "     return {\n",
    "        k:filter_motion2(p, func, fs) for k, p in data_dict.items()\n",
    "    }   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gesture(object):\n",
    "    \n",
    "    effort_keys = ['weight', 'time', 'space', 'flow', 'shape']\n",
    "    \n",
    "    weight_table = {\n",
    "        'weight': np.array([0.1, 0.3, 0.3, 0.15, 0.15]),\n",
    "        'time': np.array([0.3, 0.25, 0.25, 0.1, 0.1]),\n",
    "        'space': np.array([0.1, 0.225, 0.225, 0.225, 0.225]),\n",
    "        'flow': np.array([0.1, 0.225, 0.225, 0.225, 0.225]),\n",
    "        'shape': np.array([0.1, 0.225, 0.225, 0.225, 0.225])\n",
    "    }\n",
    "    \n",
    "    effector_table = {\n",
    "        'weight': ['head', 'leftWrist', 'rightWrist', 'leftAnkle', 'rightAnkle'],\n",
    "        'time': ['head', 'leftWrist', 'rightWrist', 'leftAnkle', 'rightAnkle'],\n",
    "        'space': ['head', 'leftWrist', 'rightWrist', 'leftAnkle', 'rightAnkle'],\n",
    "        'flow': ['head', 'leftWrist', 'rightWrist', 'leftAnkle', 'rightAnkle'],\n",
    "        'shape': ['head', 'leftWrist', 'rightWrist', 'leftAnkle', 'rightAnkle']\n",
    "    }\n",
    "    \n",
    "    def __init__(self, laban_obj):\n",
    "        \n",
    "        self.callback_table = {\n",
    "            'time': self.aggregate_effort,\n",
    "            'flow': self.aggregate_effort,\n",
    "            'shape': self.aggregate_effort,\n",
    "            'weight': self.weight_effort,\n",
    "            'space': self.space_effort\n",
    "        }\n",
    "        \n",
    "        self.trajectory_table = {\n",
    "            'weight': laban_obj.joint_speed,\n",
    "            'time': laban_obj.joint_mgacc,\n",
    "            'space': laban_obj.joint_pos,\n",
    "            'flow': laban_obj.joint_mgjrk,\n",
    "            'shape': laban_obj.joint_curvature\n",
    "        }\n",
    "        \n",
    "        self.__keyframes = laban_obj._LabanApproximator__keyframes\n",
    "        self.ngestures = len(self.__keyframes) - 1\n",
    "        self.effort_table = np.zeros((self.ngestures, len(Gesture.effort_keys)))\n",
    "        \n",
    "        for idx, key in enumerate(Gesture.effort_keys):\n",
    "            t = self.trajectory_table[key]\n",
    "            e = Gesture.effector_table[key]\n",
    "            w = Gesture.weight_table[key]\n",
    "            cb = self.callback_table[key]\n",
    "            self.__push_effort(t, e, w, cb, self.effort_table[:, idx])\n",
    "        \n",
    "    def get_motion_features(self):\n",
    "        return self.effort_table\n",
    "    \n",
    "    def aggregate_effort(self, segment_matrix, weights):\n",
    "        T = segment_matrix.shape[0]\n",
    "        mat_sum = np.sum(segment_matrix, axis=0) / T\n",
    "        return np.dot(mat_sum, weights)\n",
    "    \n",
    "    def weight_effort(self, segment_matrix, weights):\n",
    "        mat_sqr = np.power(segment_matrix, 2.)\n",
    "        mat_w = np.multiply(mat_sqr, weights)\n",
    "        mat_sum = np.sum(mat_w, axis=1)\n",
    "        return np.amax(mat_sum)\n",
    "    \n",
    "    def space_effort(self, segment_matrix, weights):\n",
    "        tot_displacement2d = segment_matrix[:, 1:] - segment_matrix[:, 0:-1]\n",
    "        tot_displacement1d = length(tot_displacement2d, axis=2)\n",
    "        tot_disp_sum = np.sum(tot_displacement1d, axis=1)\n",
    "        displacement2d = segment_matrix[:, -1] - segment_matrix[:, 0]\n",
    "        displacement1d = length(displacement2d)\n",
    "        disp_ratio = np.divide(displacement1d, tot_disp_sum + 0.001)\n",
    "        return np.dot(disp_ratio, weights)\n",
    "        \n",
    "    def __push_effort(self, mfeature, jointseg, weights, effort_func, out_arr):\n",
    "        for idx, segment in enumerate(self.__iseg(mfeature, jointseg)):\n",
    "            out_arr[idx] = effort_func(segment, weights)\n",
    "        \n",
    "    def __iseg(self, mfeature, jointseg):\n",
    "        isnd = len(mfeature['head'].shape) > 1\n",
    "        fmat = dict2mat(mfeature, jointseg, not isnd)\n",
    "        for i in range(0, len(self.__keyframes) - 1):\n",
    "            lo = self.__keyframes[i]\n",
    "            hi = self.__keyframes[i + 1]\n",
    "            yield fmat[:, lo:hi] if isnd else fmat[lo:hi, :]\n",
    "     \n",
    "    \n",
    "class LabanApproximator(object):\n",
    "    \n",
    "    __H_PAIRS = [\n",
    "        ('rightShoulder', 'rightElbow'), ('rightElbow', 'rightWrist'),\n",
    "        ('leftShoulder', 'leftElbow'), ('leftElbow', 'leftWrist'),\n",
    "        ('rightHip', 'rightKnee'), ('rightKnee', 'rightAnkle'),\n",
    "        ('leftHip', 'leftKnee'), ('leftKnee', 'leftAnkle')\n",
    "    ]\n",
    "    \n",
    "    ALL_SCALE = None\n",
    "    GESTURES_PER_BATCH = 7\n",
    "    \n",
    "    def __init__(self, lma_segment):\n",
    "        \n",
    "        data = lma_segment.joint_data\n",
    "        if LabanApproximator.ALL_SCALE:\n",
    "            data = dict_operator(self.world_scale, data)\n",
    "        \n",
    "        self.joint_pos = lfderivator(lpf_motion(), filter_motion, data)\n",
    "        \n",
    "        fs = 1. / lma_segment.meta_data['frameRate']        \n",
    "        self.joint_vel = rawderivator(velocity, self.joint_pos, fs)\n",
    "        self.joint_acc = rawderivator(acceleration, self.joint_pos, fs)\n",
    "        self.joint_jrk = rawderivator(jerk, self.joint_pos, fs)\n",
    "        \n",
    "        self.joint_curvature = {\n",
    "            k:curvature(vp, ap) for (k, vp), (_, ap)\\\n",
    "                in zip(self.joint_vel.items(), self.joint_acc.items())\n",
    "        }\n",
    "        \n",
    "        self.joint_speed = dict_operator(length, self.joint_vel)\n",
    "        self.joint_mgacc = dict_operator(length, self.joint_acc)\n",
    "        self.joint_mgjrk = dict_operator(length, self.joint_jrk)\n",
    "        self.bone_angles = self.bone_angle_array() \n",
    "        \n",
    "        self.wlen = 5\n",
    "        self.sig  = 0.75\n",
    "        self.cluster_dist1 = self.wlen\n",
    "        self.lin_weights = np.ones((self.bone_angles.shape[1], )) / self.bone_angles.shape[1]\n",
    "        \n",
    "        self.__keyframes, self.__rcurve = self.keyframes()\n",
    "        self.__gesture = Gesture(self)\n",
    "        \n",
    "\n",
    "    def get_motion_features(self):\n",
    "        return self.__gesture.get_motion_features()\n",
    "    \n",
    "    def world_scale(self, array):\n",
    "        return np.multiply(array, LabanApproximator.ALL_SCALE)\n",
    "    \n",
    "    def bone_angle_array(self):\n",
    "        p = self.joint_pos\n",
    "        root = np.array([0, 0])\n",
    "        clav = (p['leftHip'] + p['rightHip']) / 2.\n",
    "        center_bone = clav - root\n",
    "                \n",
    "        return np.asarray([\n",
    "            angle_btw(v, center_bone) for v in [\n",
    "                p[bp[1]] - p[bp[0]] for bp in LabanApproximator.__H_PAIRS\n",
    "            ]\n",
    "        ]).T\n",
    "        \n",
    "    def keyframes(self):\n",
    "        keyframes = []\n",
    "        a = self.bone_angles\n",
    "        for col in range(0, a.shape[1]):\n",
    "            curve = a[:, col]\n",
    "            salience = curve_salience(curve, self.wlen, self.sig)\n",
    "            candidkf = candidate_keyframes(salience)\n",
    "            kcluster = cluster_keyframes_simple(candidkf, self.cluster_dist1)\n",
    "            keyframes.append(decimate_keyframes(kcluster, curve))\n",
    "\n",
    "        k = reduce(np.union1d, tuple(keyframes))\n",
    "        _, _, _, cls = cluster_keyframes_kmeans(k, n_clusters=LabanApproximator.GESTURES_PER_BATCH + 1)\n",
    "        ref_curve = lincomb(a, self.lin_weights)\n",
    "        out_keyframes = decimate_keyframes(cls, ref_curve)\n",
    "        return (out_keyframes, ref_curve)\n",
    "    \n",
    "    def plt_keyframes(self, fignum=0, figsize=(10, 8)):\n",
    "        fig, axs = plt.subplots(2, 1, num=fignum, figsize=figsize)\n",
    "        pp.plt_keyframe_curve(axs[0], self.__keyframes, self.__rcurve)\n",
    "        pp.plt_keyframe_skeleton(axs[1], self.__keyframes, self.joint_pos, 200.)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMARunner(object):\n",
    "    \n",
    "    def __init__(self, video_segments):\n",
    "        \n",
    "        self.lma_list = []\n",
    "        feature_list = []\n",
    "        \n",
    "        tot = len(video_segments) - 1\n",
    "        for elp, seg in enumerate(video_segments):\n",
    "            lma = LabanApproximator(seg)\n",
    "            self.lma_list.append(lma)\n",
    "            feature = lma.get_motion_features()\n",
    "            feature_list.append(feature)\n",
    "            print_progress('[*]  Processing', elp/tot)\n",
    "        \n",
    "        self.nframes = len(self.lma_list)\n",
    "        self.ngestures = LabanApproximator.GESTURES_PER_BATCH \n",
    "        self.motion_features_raw = np.vstack(tuple(feature_list))\n",
    "        \n",
    "        '''\n",
    "        self.motion_features_log = self.motion_features_raw.copy()\n",
    "        self.motion_features_log[:, 0] = np.log10(self.motion_features_log[:, 0])\n",
    "        \n",
    "        self.weight_thresh = np.mean(self.motion_features_log[:, 0])\n",
    "        self.time_thresh = np.mean(self.motion_features_log[:, 1])\n",
    "        self.space_thresh = 0.55\n",
    "        \n",
    "        self.action_effort_encoded = self.__action_effort(self.motion_features_log)\n",
    "        self.bea_encoded_ = self.action_effort_encoded.reshape((\n",
    "            self.nframes,\n",
    "            self.ngestures,\n",
    "            self.action_effort_encoded.shape[-1]\n",
    "        ))\n",
    "        '''\n",
    "    \n",
    "    def dataframe(self):\n",
    "        cols = Gesture.effort_keys\n",
    "        return pd.DataFrame(self.motion_features_raw, columns=cols)\n",
    "    \n",
    "    def plot_keyframes_for(self, frame_num, fignum=0):\n",
    "        self.lma_list[frame_num].plt_keyframes(fignum=fignum)\n",
    "    \n",
    "    @staticmethod\n",
    "    def set_lma_hyperparams(scale=1, gestures_per_batch=7, effectors_weights=None):\n",
    "        LabanApproximator.ALL_SCALE = scale\n",
    "        LabanApproximator.GESTURES_PER_BATCH = gestures_per_batch\n",
    "        \n",
    "        if not effectors_weights:\n",
    "            return\n",
    "        \n",
    "        for bea, e, w in effectors_weights:\n",
    "            Gesture.effector_table[bea] = e\n",
    "            Gesture.weight_table[bea] = w\n",
    "        \n",
    "    '''\n",
    "    def __basic_effort(self, effort_features):\n",
    "        predicates = zip([self.weight_thresh, self.time_thresh, self.space_thresh])\n",
    "        return np_step(effort_features, predicates)\n",
    "    \n",
    "    def __action_effort(self, effort_features):\n",
    "        binary_encoding = self.__basic_effort(effort_features)\n",
    "        decimal_encoding = binary_encoding.dot(\n",
    "            1 << np.arange(binary_encoding.shape[-1] - 1, -1, -1)\n",
    "        ).astype(np.int32)\n",
    "        \n",
    "        idx = np.vstack((np.arange(binary_encoding.shape[0]), decimal_encoding)).T\n",
    "        one_hot = np.zeros((effort_features.shape[0], 8))\n",
    "        one_hot[idx[:, 0], idx[:, 1]] = 1\n",
    "        \n",
    "        return one_hot   \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
